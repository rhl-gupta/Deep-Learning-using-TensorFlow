{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Highlights of the project\n",
    "- Objective - To make a deep learning model to detect an image having digit between 0-9\n",
    "- Dataset used -  MNIST dataset  \n",
    "- ML library - TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\Rahul\\Desktop\\Mail\\Data_MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting C:\\Users\\Rahul\\Desktop\\Mail\\Data_MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting C:\\Users\\Rahul\\Desktop\\Mail\\Data_MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting C:\\Users\\Rahul\\Desktop\\Mail\\Data_MNIST\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"C:\\\\Users\\\\Rahul\\\\Desktop\\\\Mail\\\\Data_MNIST\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape/Dimensions of train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features datset : (55000, 784)\n",
      "Shape of training labels datset : (55000, 10)\n",
      "Shape of test features datset : (10000, 784)\n",
      "Shape of test features datset : (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training features datset : \" + str(X_train.shape))\n",
    "print(\"Shape of training labels datset : \" + str(Y_train.shape))\n",
    "print(\"Shape of test features datset : \" + str(X_test.shape))\n",
    "print(\"Shape of test features datset : \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations after loading the dataset\n",
    "\n",
    "- Dataset is already flattended\n",
    "- 55000 training examples\n",
    "- Image is $28\\times28$ pixel ($784 = 28\\times28$) \n",
    "- 10000 testing exmaples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x156029fd9b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADX5JREFUeJzt3W2MXOV5xvHrwl7bqXHBxsE4xo1xa6hc1BppcaOCEBWQ\nGERqp63cuC11GsSiJk2KlA+h8CFUbRXUNK9KQbKDGwcRkqoJwh9QK2w1pajEZaGOX3CCqTGyXYMh\nBHCSYvxy98MeRxvYeXaZOTNn1vf/J6125tznzLk19rVn5jwz53FECEA+ZzTdAIBmEH4gKcIPJEX4\ngaQIP5AU4QeSIvxAUoQfSIrwA0lN7eXOpnl6zNDMXu4SSOV1/URvxFFPZN2Owm97haQvSpoi6SsR\ncWdp/Rmaqd/0VZ3sEkDB1tgy4XXbftlve4qkf5B0raSlktbYXtru4wHorU7e8y+X9ExE7I2INyR9\nQ9LKetoC0G2dhH+BpP2j7h+olv0c20O2h20PH9PRDnYHoE5dP9sfEesiYjAiBgc0vdu7AzBBnYT/\noKSFo+6fXy0DMAl0Ev7HJS2xfYHtaZI+KGlTPW0B6La2h/oi4rjtP5f0rxoZ6tsQEbtq6wxAV3U0\nzh8RD0l6qKZeAPQQH+8FkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kR\nfiCpnl66G6ehM6YUy0+vv6Rlbdf77ipu+/61f1asT93yRLGOMo78QFKEH0iK8ANJEX4gKcIPJEX4\ngaQIP5AU4/womvruhcX6058+p1h/9sqvFKrTitu+8svl+tyJT0iLMXDkB5Ii/EBShB9IivADSRF+\nICnCDyRF+IGkOhrnt71P0hFJJyQdj4jBOppC70xdvKhYf+r2ucV6eRy/7Kb9lxXr8/7jpWL9RNt7\nhlTPh3x+OyLK/0oA+g4v+4GkOg1/SNps+wnbQ3U0BKA3On3Zf3lEHLR9rqSHbX8/Ih4ZvUL1R2FI\nkmboFzrcHYC6dHTkj4iD1e/Dkh6QtHyMddZFxGBEDA5oeie7A1CjtsNve6btWaduS3qvpJ11NQag\nuzp52T9P0gO2Tz3O1yPiX2rpCkDXtR3+iNgr6Tdq7AVd4IHyd+J33zGnWH/26vbH8SVp8eYPt6xd\nNPRUcduTr+/paN8oY6gPSIrwA0kRfiApwg8kRfiBpAg/kBSX7j7N/eDL5dHYZ69e39Hj/8p3PlSs\nL/mTJ1vWTna0Z3SKIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMU4/2ngmS+8p3Xt+rvG2br893/x\nw62/kitJFw7tKtZjnL2jORz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApxvkngTdWXFqsP7DqCy1r\nUzyjuO2438f/0+8V63GSibInK478QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5DUuOP8tjdIul7S4Yi4\nuFo2R9I3JS2StE/S6oj4UffazO2c258t1n99Wuux/Gt2v7+47YWfeq1YP8E4/mlrIkf+r0pa8aZl\nt0raEhFLJG2p7gOYRMYNf0Q8IunlNy1eKWljdXujpFU19wWgy9p9zz8vIg5Vt5+XNK+mfgD0SMcn\n/CIiVLhUm+0h28O2h4/paKe7A1CTdsP/gu35klT9PtxqxYhYFxGDETE4oOlt7g5A3doN/yZJa6vb\nayU9WE87AHpl3PDbvl/SY5Iusn3A9o2S7pR0je09kq6u7gOYRMYd54+INS1KV9XcC1r4+ILNbW/7\n2sbzi/Wz9zzW9mNjcuMTfkBShB9IivADSRF+ICnCDyRF+IGkuHR3H3j1j1tPsS1JV8zYVqxftv13\nW9bOvve7bfWE0x9HfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IinH+PvDK7/yko+1/uum8lrUzY29H\nj93XzphSrnPZ8SKO/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOP8fWD+7PI02eN5xw9P1tRJbx29\n9tJi/aWbflqsXzzvULF+5PentawdP/R8cdsMOPIDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFLjjvPb\n3iDpekmHI+Liatkdkm6S9GK12m0R8VC3mpzspp43r1hff9F94zzCmfU1U7MpZ59VrK96bE/L2h/M\n+lJx27POeEdbPZ3ya1/+o5a183+Pcf6JHPm/KmnFGMs/HxHLqh+CD0wy44Y/Ih6R9HIPegHQQ528\n5/+Y7e22N9ieXVtHAHqi3fDfLWmxpGWSDkn6bKsVbQ/ZHrY9fExH29wdgLq1Ff6IeCEiTkTESUnr\nJS0vrLsuIgYjYnBA09vtE0DN2gq/7fmj7n5A0s562gHQKxMZ6rtf0pWS5to+IOlTkq60vUxSSNon\n6eYu9gigC8YNf0SsGWPxPV3o5fQ1MFAs/9LU/h3HP/yR3yrWV938nWJ96Kz/LVQ7G8cfzztndTYf\nwumOT/gBSRF+ICnCDyRF+IGkCD+QFOEHkuLS3T0QR44U6+tefVexXh4uK5sy95xiff+HLyrWd9xy\nV9v7btqr/zejZe3cHvbRrzjyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSjPP3wIlXXi3W7z9Qnqp6\n6KwHi/XLPrm1Ze3Sv95b3Hb1mVuK9X72Vy8uLdbf9fHWX+k9XnczkxBHfiApwg8kRfiBpAg/kBTh\nB5Ii/EBShB9IinH+PvD6P84v1o9+5lix/pnz/rvOdnrmWJwo1pf++43F+oV/+cNi/fhz+992T5lw\n5AeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpMYd57e9UNLXJM2TFJLWRcQXbc+R9E1JiyTtk7Q6In7U\nvVZPX7/49e8W61v/pjzF9xWtL0/fdSfiZLE+OPyHLWvT/nl2cdvF9z5WrPOd/M5M5Mh/XNInImKp\npPdI+qjtpZJulbQlIpZI2lLdBzBJjBv+iDgUEU9Wt49I2i1pgaSVkjZWq22UtKpbTQKo39t6z297\nkaRLJG2VNC8iDlWl5zXytgDAJDHh8Ns+U9K3JN0SEa+NrkVEaOR8wFjbDdketj18TEc7ahZAfSYU\nftsDGgn+fRHx7WrxC7bnV/X5kg6PtW1ErIuIwYgYHND0OnoGUINxw2/bku6RtDsiPjeqtEnS2ur2\nWknlS8wC6CsT+UrvZZJukLTD9rZq2W2S7pT0T7ZvlPScpNXdaRGd+NVHbyjWvXNWsX7Bl3YV63Gi\nPNR37pHvF+tozrjhj4hHJblF+ap62wHQK3zCD0iK8ANJEX4gKcIPJEX4gaQIP5AUl+4+DSy9+yMt\na4s+/V/FbeN4+Yux5YtrYzLjyA8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHOPwn87eJlxfpC/WfL\n2pjXVgPEkR9Ii/ADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU\n4QeSGjf8thfa/jfbT9neZfsvquV32D5oe1v1c1332wVQl4lczOO4pE9ExJO2Z0l6wvbDVe3zEfH3\n3WsPQLeMG/6IOCTpUHX7iO3dkhZ0uzEA3fW23vPbXiTpEklbq0Ufs73d9gbbs1tsM2R72PbwMR3t\nqFkA9Zlw+G2fKelbkm6JiNck3S1psaRlGnll8NmxtouIdRExGBGDA5peQ8sA6jCh8Nse0Ejw74uI\nb0tSRLwQESci4qSk9ZKWd69NAHWbyNl+S7pH0u6I+Nyo5fNHrfYBSTvrbw9At0zkbP9lkm6QtMP2\ntmrZbZLW2F6mkatD75N0c1c6BNAVEznb/6gkj1F6qP52APQKn/ADkiL8QFKEH0iK8ANJEX4gKcIP\nJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k5Yjo3c7sFyU9N2rRXEkv9ayBt6dfe+vXviR6\na1edvb07It45kRV7Gv637NwejojBxhoo6Nfe+rUvid7a1VRvvOwHkiL8QFJNh39dw/sv6dfe+rUv\nid7a1Uhvjb7nB9Ccpo/8ABrSSPhtr7D9A9vP2L61iR5asb3P9o5q5uHhhnvZYPuw7Z2jls2x/bDt\nPdXvMadJa6i3vpi5uTCzdKPPXb/NeN3zl/22p0h6WtI1kg5IelzSmoh4qqeNtGB7n6TBiGh8TNj2\nFZJ+LOlrEXFxtezvJL0cEXdWfzhnR8Qn+6S3OyT9uOmZm6sJZeaPnlla0ipJH1KDz12hr9Vq4Hlr\n4si/XNIzEbE3It6Q9A1JKxvoo+9FxCOSXn7T4pWSNla3N2rkP0/PteitL0TEoYh4srp9RNKpmaUb\nfe4KfTWiifAvkLR/1P0D6q8pv0PSZttP2B5qupkxzKumTZek5yXNa7KZMYw7c3MvvWlm6b557tqZ\n8bpunPB7q8sjYpmkayV9tHp525di5D1bPw3XTGjm5l4ZY2bpn2nyuWt3xuu6NRH+g5IWjrp/frWs\nL0TEwer3YUkPqP9mH37h1CSp1e/DDffzM/00c/NYM0urD567fprxuonwPy5pie0LbE+T9EFJmxro\n4y1sz6xOxMj2TEnvVf/NPrxJ0trq9lpJDzbYy8/pl5mbW80srYafu76b8Toiev4j6TqNnPH/H0m3\nN9FDi74WS/pe9bOr6d4k3a+Rl4HHNHJu5EZJ50jaImmPpM2S5vRRb/dK2iFpu0aCNr+h3i7XyEv6\n7ZK2VT/XNf3cFfpq5HnjE35AUpzwA5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q1P8D4/EK73AJ\nAvYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1560285d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the value of index to plot the respective training example\n",
    "index=3\n",
    "plt.imshow(X_train[index,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "Y_train = Y_train/255\n",
    "X_test = X_test/255\n",
    "Y_test = Y_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Computational TF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136\n"
     ]
    }
   ],
   "source": [
    "# Create placeholders for X(features) and Y(labels)\n",
    "x = tf.placeholder(tf.float32,shape=(None,784))\n",
    "y = tf.placeholder(tf.float32,shape=(None,10))\n",
    "\n",
    "# Defining & initializing the weights and bias\n",
    "w = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Calculating the logit (xw+b)\n",
    "z = tf.add(tf.matmul(x,w),b)\n",
    "\n",
    "# Passing logit through activation function (softmax is used here)\n",
    "yhat = tf.nn.softmax(z)\n",
    "\n",
    "# Calculating the cost (cross entropy is used here)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=z,labels=y)\n",
    "\n",
    "# Backward propagation using Gradient Descent\n",
    "training_the_model = tf.train.AdadeltaOptimizer(learning_rate=0.7).minimize(cross_entropy)\n",
    "\n",
    "# Starting the TF session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Making small batches for 100 examples and iterating 1000 times \n",
    "for _ in range(1900):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(300)\n",
    "    sess.run(training_the_model, feed_dict={x: batch_xs, y: batch_ys})\n",
    "    \n",
    "# Calculating the accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(yhat,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Passing test dataset and calculating the accuracy\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
